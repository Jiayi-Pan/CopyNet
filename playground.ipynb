{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from random import shuffle, seed\n",
    "\n",
    "from dataset import SequencePairDataset\n",
    "from model.encoder_decoder import EncoderDecoder\n",
    "from evaluate import evaluate\n",
    "from utils import to_np, trim_seqs\n",
    "import bcolz, pickle\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cleanup.golden.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = data[:int(len(data)*0.8)]\n",
    "raw_test_data = data[int(len(data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_data(raw_data):\n",
    "    train_data = []\n",
    "    for dp in raw_data:\n",
    "        train_data.append((\n",
    "            dp['natural'],\n",
    "            dp['raw_ltl']\n",
    "        ))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = parse_raw_data(raw_train_data)\n",
    "test_data = parse_raw_data(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "train_dataset = SequencePairDataset(train_data,\n",
    "                                    use_cuda=CUDA,\n",
    "                                    is_val=False,\n",
    "                                    use_extended_vocab=True)\n",
    "\n",
    "val_dataset = SequencePairDataset(test_data,lang=train_dataset.lang,\n",
    "                                    use_cuda=CUDA,\n",
    "                                    is_val=True,\n",
    "                                    use_extended_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_for_input_language(lang):\n",
    "    # source for this code: https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76\n",
    "    glove_path = 'glove/'\n",
    "    vectors = bcolz.open(glove_path + '6B.50.dat')[:]\n",
    "    words = pickle.load(open(glove_path + '6B.50_words.pkl', 'rb'))\n",
    "    word2idx = pickle.load(open(glove_path + '6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "    glove = {w: vectors[word2idx[w]] for w in words}\n",
    "\n",
    "    target_vocab = lang.idx_to_tok\n",
    "\n",
    "    emb_dim = 50\n",
    "\n",
    "    matrix_len = len(target_vocab)\n",
    "    weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "    words_found = 0\n",
    "    i = 0\n",
    "\n",
    "    for word in target_vocab:\n",
    "        try:\n",
    "            # print(target_vocab[word])\n",
    "            weights_matrix[i] = glove[target_vocab[word]]\n",
    "            # print(i)\n",
    "            # print(word)\n",
    "            words_found += 1\n",
    "            i += 1\n",
    "        except KeyError:\n",
    "            weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim,))\n",
    "\n",
    "    return weights_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE = True\n",
    "if GLOVE:\n",
    "    glove_map = vectors_for_input_language(train_dataset.lang)\n",
    "    # glove_encoder = TestEncoderRNN(\n",
    "    #     input_lang.n_words, embed_size, hidden_size, glove_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.lang.idx_to_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CopyNet Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64 # same with the dataset length\n",
    "EMBED_SIZE = 50\n",
    "HIDDEN_SIZE = 256\n",
    "MODEL_NAME = \"TEST\"\n",
    "encoder_decoder = EncoderDecoder(train_dataset.lang,\n",
    "                                    max_length=MAX_LEN,\n",
    "                                    embedding_size=EMBED_SIZE,\n",
    "                                    hidden_size= HIDDEN_SIZE,\n",
    "                                    decoder_type = 'copy')\n",
    "encoder_decoder = encoder_decoder.cuda() if CUDA else encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([195, 50])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder.encoder.embedding.weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace the randomly initialized embedding with glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5152,  0.8012, -0.1373,  ..., -1.1572, -0.0800,  0.0821],\n",
       "        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
       "        [ 0.6805, -0.0393,  0.3019,  ..., -0.0733, -0.0647, -0.2604],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder.encoder.embedding.weight.data.copy_(torch.from_numpy(glove_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:14<00:00,  5.89it/s]\n",
      "/home/celeste/miniconda3/envs/GPML/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]/home/celeste/code/0913/copynet/evaluate.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  input_variable = Variable(\n",
      "/home/celeste/code/0913/copynet/evaluate.py:36: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  target_variable = Variable(target_idxs[order, :], volatile=True)\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 12, 2]\n",
      "val loss: 5.92090, val score: 0.24815\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:12<00:00,  6.96it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 12, 2]\n",
      "val loss: 11.76815, val score: 0.38848\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.21it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 12, 2]\n",
      "val loss: 28.51410, val score: 0.51699\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.12it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: 60.49424, val score: 0.60118\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.11it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: 124.37651, val score: 0.67208\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.15it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: 159.89110, val score: 0.69276\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.39it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -10096.18736, val score: 0.81241\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.18it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -160.96440, val score: 0.87149\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.12it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -158.89162, val score: 0.88479\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.21it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -134.46446, val score: 0.91433\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.13it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -164.46170, val score: 0.91433\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.11it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -116.49741, val score: 0.92171\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.17it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -90.29626, val score: 0.94092\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.42it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -91.09345, val score: 0.94978\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:12<00:00,  7.04it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -87.12136, val score: 0.95569\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.19it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -86.06262, val score: 0.96012\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.26it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -94.31878, val score: 0.94830\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.17it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -86.36654, val score: 0.95569\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:12<00:00,  7.02it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -84.47589, val score: 0.95864\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.37it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -88.74404, val score: 0.96012\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.20it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -75.66516, val score: 0.96603\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:12<00:00,  7.01it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -76.78558, val score: 0.96603\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.19it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -86.79571, val score: 0.95864\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.18it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -78.93122, val score: 0.96012\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.16it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -75.84130, val score: 0.97194\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:12<00:00,  6.98it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -77.53520, val score: 0.97046\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.30it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -75.83220, val score: 0.97046\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.20it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -77.01484, val score: 0.97046\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 85/85 [00:11<00:00,  7.18it/s]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output:\n",
      "              [[1, 6, 8, 28, 14, 17, 6, 13, 2]]\n",
      "              [1, 6, 8, 28, 14, 17, 6, 13, 2]\n",
      "val loss: -74.73236, val score: 0.96307\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 27/85 [00:03<00:07,  7.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/celeste/code/0913/copynet/playground.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39m'\u001b[39m\u001b[39m./logs/\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (MODEL_NAME, \u001b[39mstr\u001b[39m(\u001b[39mint\u001b[39m(time\u001b[39m.\u001b[39mtime()))))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m train(encoder_decoder,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         train_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         model_name\u001b[39m=\u001b[39;49mMODEL_NAME,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         val_data_loader\u001b[39m=\u001b[39;49mval_data_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         keep_prob\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         teacher_forcing_schedule\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marange(\u001b[39m1.0\u001b[39;49m, \u001b[39m0.0\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1.0\u001b[39;49m\u001b[39m/\u001b[39;49mepochs),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         max_length\u001b[39m=\u001b[39;49mencoder_decoder\u001b[39m.\u001b[39;49mdecoder\u001b[39m.\u001b[39;49mmax_length,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bpop/home/celeste/code/0913/copynet/playground.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         writer\u001b[39m=\u001b[39;49mwriter,)\n",
      "File \u001b[0;32m~/code/0913/copynet/train.py:50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encoder_decoder, train_data_loader, model_name, val_data_loader, keep_prob, teacher_forcing_schedule, lr, max_length, writer)\u001b[0m\n\u001b[1;32m     47\u001b[0m target_variable \u001b[39m=\u001b[39m Variable(target_idxs[order, :])\n\u001b[1;32m     49\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 50\u001b[0m output_log_probs, output_seqs \u001b[39m=\u001b[39m encoder_decoder(input_variable,\n\u001b[1;32m     51\u001b[0m                                                 \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m     52\u001b[0m                                                     sorted_lengths),\n\u001b[1;32m     53\u001b[0m                                                 targets\u001b[39m=\u001b[39;49mtarget_variable,\n\u001b[1;32m     54\u001b[0m                                                 keep_prob\u001b[39m=\u001b[39;49mkeep_prob,\n\u001b[1;32m     55\u001b[0m                                                 teacher_forcing\u001b[39m=\u001b[39;49mteacher_forcing)\n\u001b[1;32m     57\u001b[0m batch_size \u001b[39m=\u001b[39m input_variable\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     59\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output_log_probs\u001b[39m.\u001b[39mview(\n\u001b[1;32m     60\u001b[0m     batch_size \u001b[39m*\u001b[39m max_length, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/GPML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/0913/copynet/model/encoder_decoder.py:38\u001b[0m, in \u001b[0;36mEncoderDecoder.forward\u001b[0;34m(self, inputs, lengths, targets, keep_prob, teacher_forcing)\u001b[0m\n\u001b[1;32m     36\u001b[0m batch_size \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39minit_hidden(batch_size)\n\u001b[0;32m---> 38\u001b[0m encoder_outputs, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(inputs, hidden, lengths)\n\u001b[1;32m     39\u001b[0m decoder_outputs, sampled_idxs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(encoder_outputs,\n\u001b[1;32m     40\u001b[0m                                              inputs,\n\u001b[1;32m     41\u001b[0m                                              hidden,\n\u001b[1;32m     42\u001b[0m                                              targets\u001b[39m=\u001b[39mtargets,\n\u001b[1;32m     43\u001b[0m                                              teacher_forcing\u001b[39m=\u001b[39mteacher_forcing)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m decoder_outputs, sampled_idxs\n",
      "File \u001b[0;32m~/miniconda3/envs/GPML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/0913/copynet/model/encoder.py:20\u001b[0m, in \u001b[0;36mEncoderRNN.forward\u001b[0;34m(self, iput, hidden, lengths)\u001b[0m\n\u001b[1;32m     18\u001b[0m iput \u001b[39m=\u001b[39m iput\u001b[39m.\u001b[39mmasked_fill(iput \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mnum_embeddings, \u001b[39m3\u001b[39m)  \u001b[39m# replace OOV words with <UNK> before embedding\u001b[39;00m\n\u001b[1;32m     19\u001b[0m embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(iput)\n\u001b[0;32m---> 20\u001b[0m packed_embedded \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mrnn\u001b[39m.\u001b[39;49mpack_padded_sequence(embedded, lengths, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru\u001b[39m.\u001b[39mflatten_parameters()\n\u001b[1;32m     22\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(packed_embedded, hidden)\n",
      "File \u001b[0;32m~/miniconda3/envs/GPML/lib/python3.9/site-packages/torch/nn/utils/rnn.py:260\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    256\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    257\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    259\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 260\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[1;32m    261\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "writer = SummaryWriter('./logs/%s_%s' % (MODEL_NAME, str(int(time.time()))))\n",
    "train(encoder_decoder,\n",
    "        train_data_loader,\n",
    "        model_name=MODEL_NAME,\n",
    "        val_data_loader=val_data_loader,\n",
    "        keep_prob=1.0,\n",
    "        teacher_forcing_schedule=np.arange(1.0, 0.0, -1.0/epochs),\n",
    "        lr=0.001,\n",
    "        max_length=encoder_decoder.decoder.max_length,\n",
    "        writer=writer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('GPML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d95a699133b36d6ec89295fddf252f8d8894a548ca31962f7ce16dda03c5923f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
